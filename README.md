# Feminism_analysis
这个仓库储存了分析“女权主义”和“女性主义”两个译介词在我国媒体上的话语取向差距的分析代码和原始数据。  
这个文档描述了各个文件的作用，请按照介绍的顺序使用它们。  
该文档及文档中代码作者为中国人民大学新闻学院张轩。  
## Python 部分  
### 女权主义原始文本 - 副本.txt和女性主义原始文本 - 副本.txt  
这是两个从慧科下载的原始语料库，女权主义约两百万字，女性主义约四百五十万字。  
### re_femi_raw.py  
该代码用于处理原始文档，初步清洗部分废话，并逐行将报道及其编码写入csv。运行完成后请大致检查文件，如有少数内容出现行列对应错误或者编码空白等问题， 可以直接将其删除或者人工编码。正常操作下应当共有2222条文档。  
### get_stopwords.py、baidu_stopwords.txt等stopwords文本文档及保留词
本文使用了川大停用词、哈工大停用词、百度停用词及中文停用词的并集作为停用词库，由该代码文档处理生成。作者在并集的基础上按照需求添加了小部分，可以直接使用finalstopwords.txt这个文档。保留词用于分词过程，人名为主。  
### re_femi_seg.py  
分词和清洗停用词，写入新的csv文档。
### re_femi_emo.py、情感词汇本体.csv、情感词汇本体库说明文档.doc    
情感分析，该代码计算每篇文档的情感分数以及情感强度，并输出女性主义和女权主义各年不同情感词汇的数量，会以十个字典的形式直接打印，请注意保存。具体赋值请参照大连理工大学情感词汇本体及使用说明。为了计算方便，笔者删除了所有情感极性赋值为3的词语。这部分耗时约2.5小时
### emo_store.py  
考虑到前一程序输出的结果比较简单，可以直接复制过来进行操作，所以这里采取了并不优雅的方式将情感词汇小类转变为七种大类，结果直接以十个字典的形式打印，请注意保存。  
## R语言部分
### STM code.Rmd、R数据.RData  
STM在python上好像还没有可以直接调用的库，因此这里采用R语言进行后续分析。  
请注意将python处理的“分词结果.csv”转换为“分词结果.xlsx” 。  
全部代码都在STM code.Rmd这个文件里，已经写好了代码注释，这部分耗时约3小时。   
R代码会生成一个“cor_matrix.xlsx”文件，用于导入gephi制作语义网络图。  
## Acknowledgement
感谢R语言 STM的最初作者：Roberts, M. E., Stewart, B. M., & Tingley, D. (2019). stm: An R Package for Structural Topic Models. Journal of Statistical Software, 91(2), 1–40. https://doi.org/10.18637/jss.v091.i02   
感谢CSDN思想在拧紧，他用比较精干的语言描述了如何复现大部分原作者的代码，给我节省了很多时间：   
https://blog.csdn.net/what_how_why2020/article/details/122889758   
感谢人民大学新闻学院张伊妍老师细致的指导。  
